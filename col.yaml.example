# Example COL configuration file
# Copy this to col.yaml and customize for your needs

# Default LLM provider (openai, anthropic, groq)
default_provider: openai

# Default model for the provider
# OpenAI: gpt-4o, gpt-4-turbo, gpt-3.5-turbo
# Anthropic: claude-sonnet-4-20250514, claude-opus-4-20250514
# Groq: llama-3.3-70b-versatile, mixtral-8x7b-32768
default_model: gpt-4o

# Default filenames
default_context_file: context.json
default_output_file: response.json
